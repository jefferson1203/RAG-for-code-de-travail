# üìö Documentation Technique ‚Äì Assistant Juridique RAG (Code du Travail)

## 1. Pr√©sentation du Projet

Ce projet impl√©mente un assistant juridique bas√© sur le paradigme **RAG** (Retrieval-Augmented Generation) pour r√©pondre √† des questions sur le Code du Travail fran√ßais. Il combine une **recherche hybride** (s√©mantique + lexicale) et la **g√©n√©ration de r√©ponses contextualis√©es** via un **LLM (Gemini)**, le tout orchestr√© avec **LangChain** et une interface **Streamlit**.

---

## 2. Architecture du Syst√®me

- **Chargement & D√©coupage** : Extraction du texte du PDF, d√©coupage intelligent en *chunks* enrichis de m√©tadonn√©es (page, titre, article, etc.).
- **Vectorisation & Indexation** : G√©n√©ration d‚Äô**embeddings** pour chaque chunk et stockage dans **ChromaDB** (base vectorielle persistante).
- **Recherche Hybride** : Combinaison d‚Äôun **retriever s√©mantique** (embeddings) et d‚Äôun **retriever BM25** (lexical) pour maximiser la pertinence.
- **G√©n√©ration** : Utilisation de **Gemini** (via LangChain) pour synth√©tiser une r√©ponse √† partir des chunks r√©cup√©r√©s.
- **Interface Utilisateur** : Application web interactive avec **Streamlit**.

---

## 3. Fonctionnement Global

### üîπ Chargement du PDF
Le fichier PDF est charg√© depuis `data` et d√©coup√© en chunks √† l‚Äôaide de r√®gles adapt√©es √† la structure du Code du Travail (articles, titres, chapitres‚Ä¶).

### üîπ Vectorisation & Indexation
Chaque chunk est transform√© en **embedding** (mod√®le HuggingFace multilingue) et stock√© dans **ChromaDB** avec ses m√©tadonn√©es.

### üîπ Recherche Hybride
Lorsqu‚Äôune question est pos√©e :
- Recherche s√©mantique (similarit√© vectorielle)
- Recherche lexicale (BM25)
- Fusion des r√©sultats pour une meilleure couverture

### üîπ G√©n√©ration de la R√©ponse
Les chunks les plus pertinents sont transmis √† **Gemini** via **LangChain**, qui g√©n√®re une r√©ponse synth√©tique et cite les sources.

### üîπ Affichage & Interaction
L‚Äôutilisateur interagit via **Streamlit**, peut ajuster les param√®tres du mod√®le et visualiser les sources des r√©ponses.

---

## 4. Principales Fonctions et Modules

- a. Chargement et D√©coupage 
```
@st.cache_data(show_spinner=False)
def load_documents() -> Optional[List[Any]]:
    """
    Charge le PDF et retourne une liste de documents (pages).
    Utilise PyPDFLoader.
    """
```

```
@st.cache_data(show_spinner=False)
def load_documents() -> Optional[List[Any]]:
    """
    Charge le PDF et retourne une liste de documents (pages).
    Utilise PyPDFLoader.
    """
```
- b. Embeddings et Base Vectorielle
```
@st.cache_resource
def get_embedding_model():
    """
    Initialise le mod√®le d'embeddings HuggingFace.
    """
``` 

```
@st.cache_resource
def get_vectorstore():
    """
    Cr√©e ou charge la base ChromaDB persistante.
    """
```
- c. G√©n√©ration et Cha√Æne RAG 
```
@st.cache_resource
def get_llm(_params: Dict[str, Any]) -> Optional[Any]:
    """
    Initialise le mod√®le Gemini (via LangChain).
    """
```

```
@st.cache_resource
def initialize_rag_system():
    """
    Configure la cha√Æne RAG compl√®te (retrievers hybrides, prompt, LLM).
    """
```

---

## 5. Param√©trage et Interface

- **Mod√®le Gemini** : S√©lection entre plusieurs versions (ex. `gemini-2.0-flash`, `gemini-1.5-pro`)
- **Temperature** : Contr√¥le la cr√©ativit√© du LLM (0 = factuel, 1 = cr√©atif)
- **Top_p** : Diversit√© des r√©ponses
- **Historique de chat** : Conservation des √©changes utilisateur/assistant

---

## 6. Gestion des Erreurs & Robustesse

- Validation des entr√©es (PDF, cl√©s API)
- Gestion des erreurs de chargement (PDF, embeddings, ChromaDB)
- Fallback automatique sur le retriever s√©mantique si BM25 √©choue
- Messages d‚Äôerreur utilisateur clairs dans l‚Äôinterface
- Mise en cache pour acc√©l√©rer les traitements et √©viter les rechargements inutiles

---

## 7. Optimisations

- **Performance** : Caching Streamlit, embeddings multilingues optimis√©s, d√©coupage intelligent
- **Qualit√© des r√©ponses** : Fusion des retrievers, prompt engineering sp√©cialis√©, gestion des sources
- **Scalabilit√©** : ChromaDB persistante, d√©coupage modulaire du code

---

## 8. √âvaluation

- **Ragas** : √âvaluation automatique sur trois axes :
  - *Context Relevancy*
  - *Faithfulness*
  - *Answer Accuracy*
- **Jeu de donn√©es d‚Äô√©valuation** : Fichier `eval_dataset.json` avec questions et r√©ponses attendues

---

## 9. D√©ploiement

### üîπ Lancement local :

**Pr√©requis** :
- Python 3.8+
- Fichier `.env` avec les cl√©s API Google et LangChain
- PDF du Code du Travail dans `data`

**Installation des d√©pendances** :
```bash
pip install -r requirements.txt
```
---

## 10. Structure des Dossiers
```bash
data/                    # PDF(s) et jeu d‚Äô√©valuation
chroma_db_codetravail/   # Base vectorielle persistante
rag_system.py            # Script principal Streamlit
.env                     # Cl√©s API
requirements.txt         # D√©pendances
```

---

## 11. Technologies Utilis√©es üõ†Ô∏è
| Technologie     | R√¥le                                                         |
| --------------- | ------------------------------------------------------------ |
| **Streamlit**   | Interface utilisateur interactive                            |
| **LangChain**   | Orchestration de la cha√Æne RAG (Recherche + G√©n√©ration)      |
| **ChromaDB**    | Base de donn√©es vectorielle persistante                      |
| **Gemini**      | LLM (Large Language Model) utilis√© pour g√©n√©rer les r√©ponses |
| **HuggingFace** | G√©n√©ration des embeddings multilingues                       |
| **Ragas**       | √âvaluation automatique des r√©ponses g√©n√©r√©es                 |



---

## 12. Auteurs üë•
- Jefferson
- Ruben
- Lucas
- Henoc
- Haiayan

